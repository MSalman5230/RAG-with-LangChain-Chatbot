{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.schema import SystemMessage,HumanMessage,AIMessage\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.embeddings import GPT4AllEmbeddings,OllamaEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    }
   ],
   "source": [
    "#Loading Data and creating Vector\n",
    "loader=WebBaseLoader(\"https://en.wikipedia.org/wiki/Assam\")\n",
    "data=loader.load()\n",
    "\n",
    "text_splits=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=300)\n",
    "all_splits=text_splits.split_documents(data)\n",
    "print(len(all_splits))\n",
    "vectorstore = Chroma.from_documents(documents=all_splits,\n",
    "                                        embedding=OllamaEmbeddings(model=\"mistral\"),persist_directory=\"./chroma_db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating ChatModel using Ollama\n",
    "chat_model = ChatOllama(base_url=\"http://172.17.10.68:11434\", model=\"mistral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt making function\n",
    "def augment_prompt(query: str)->str:\n",
    "    # get top 3 results from knowledge base. You can play with k to tune the answers, it also depend on how your knowledge was stored.ie Chuck Size etc\n",
    "    results = vectorstore.similarity_search(query, k=2)  # result also return the source documents as metadata\n",
    "    # get the text from the results\n",
    "    source_knowledge = \"\\n\".join([x.page_content for x in results])\n",
    "    # feed source_knowledge to construct a augmented prompt\n",
    "\n",
    "    # Can try to play around the initial part prompt\n",
    "    # Using the contexts below, answer the query. OR\n",
    "    # Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "    augmented_prompt = f\"\"\"Use the following pieces of information to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "    Contexts:\n",
    "    {source_knowledge}\n",
    "    Query: {query}\"\"\"\n",
    "    return augmented_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\MegaSync\\Projects\\Git\\Ollama-LangChain-Chatbot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Assam is located in the northeastern part of India. It shares its borders with several countries including Bangladesh and Bhutan, as well as Indian states like West Bengal, Bihar, and Arunachal Pradesh.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial Conversation (1st query)\n",
    "messages=[SystemMessage(content=\"You helpful AI which only answers from information provided\")]\n",
    "#messages=[]\n",
    "query=\"Assam is located in which part of India?\"\n",
    "prompt = HumanMessage(\n",
    "    content=augment_prompt(query)\n",
    ")\n",
    "messages.append(prompt)\n",
    "\n",
    "res = chat_model(messages)\n",
    "messages.append(res)\n",
    "res.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' I cannot provide an answer with the given context as it does not mention the population of Assam or any specific data related to it.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2nd query\n",
    "query=\"What is the population?\"\n",
    "prompt = HumanMessage(\n",
    "    content=augment_prompt(query)\n",
    ")\n",
    "messages.append(prompt)\n",
    "\n",
    "res = chat_model(messages)\n",
    "messages.append(res)\n",
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=' I cannot provide an answer with the given context as it does not mention the population of Assam or any specific data related to it.')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only RAG, No Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    }
   ],
   "source": [
    "#Loading Data and creating Vector\n",
    "loader=WebBaseLoader(\"https://en.wikipedia.org/wiki/Assam\")\n",
    "data=loader.load()\n",
    "\n",
    "text_splits=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=300)\n",
    "all_splits=text_splits.split_documents(data)\n",
    "print(len(all_splits))\n",
    "vectorstore = Chroma.from_documents(documents=all_splits,\n",
    "                                        embedding=OllamaEmbeddings(model=\"mistral\"),persist_directory=\"./chroma_db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Query Model\n",
    "query_model = Ollama(base_url=\"http://172.17.10.68:11434\", model=\"mistral\")\n",
    "\n",
    "\n",
    "# Get a default QA prompt template from langchain hub https://smith.langchain.com/hub\n",
    "from langchain import hub\n",
    "QA_CHAIN_PROMPT = hub.pull(\"rlm/rag-prompt-mistral\") #rlm/rag-prompt-mistral \"rlm/rag-prompt-llama\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup RetrievalQA from langchain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "        query_model,\n",
    "        retriever=vectorstore.as_retriever(),\n",
    "        chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\MegaSync\\Projects\\Git\\Ollama-LangChain-Chatbot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Assam is located in which part of India?',\n",
       " 'result': ' Assam is a region located in northeastern India. Historically, it was home to the Ahom kingdom which was weakened and annexed by external forces due to internal political rivalries. Presently, Assam has significant population of indigenous tribes including the Karbi, and has seen demands for autonomous statehood or even a separate state.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ask a question\n",
    "question = f\"Assam is located in which part of India?\"\n",
    "result = qa_chain({\"query\": question})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Assam is a region located in northeastern India. Historically, it was home to the Ahom kingdom which was weakened and annexed by external forces due to internal political rivalries. Presently, Assam has significant population of indigenous tribes including the Karbi, and has seen demands for autonomous statehood or even a separate state.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#Loading Data and creating Vector\n",
    "loader=WebBaseLoader(\"https://example.com/\")\n",
    "data=loader.load()\n",
    "\n",
    "text_splits=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=300)\n",
    "all_splits=text_splits.split_documents(data)\n",
    "print(len(all_splits))\n",
    "vectorstore = Chroma.from_documents(documents=all_splits,\n",
    "                                        embedding=OllamaEmbeddings(model=\"mistral\"), persist_directory=\"./chroma_db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVE 751 document(s) from langchain collection\n",
      "REMOVE 120 document(s) from ff1d0b1a-8a8e-4659-a5f4-4b3c30b516fc collection\n",
      "REMOVE 191 document(s) from 22235f9b-301e-4371-9abb-e157b1eefaed collection\n",
      "REMOVE 191 document(s) from 4613a3f1-5073-4388-affc-55881469788a collection\n",
      "REMOVE 191 document(s) from b48a2be0-f4a0-4df2-ad03-603322775bdd collection\n",
      "REMOVE 120 document(s) from bbad8923-5a7b-4757-82f1-a2802f223781 collection\n",
      "REMOVE 191 document(s) from 3c44d672-061a-4225-a017-a74908be1443 collection\n",
      "REMOVE 641 document(s) from 4f024bb4-0159-4dae-b097-dcdfff168611 collection\n",
      "REMOVE 98 document(s) from a19eb05c-a40a-48ed-9e1e-9df2acc4a9b1 collection\n",
      "REMOVE 191 document(s) from c5797a36-0a1e-44eb-98a6-618ded9872e5 collection\n",
      "REMOVE 213 document(s) from 5470305f-7cd1-43c0-9f4c-cda7164083d0 collection\n",
      "REMOVE 98 document(s) from 6f2d7985-70f9-47e8-b1e7-b957de26ec7a collection\n",
      "REMOVE 1 document(s) from aaf8271f-7145-4b7d-9c15-e2777de9ae5d collection\n"
     ]
    }
   ],
   "source": [
    "# Clearing the collections\n",
    "for collection in vectorstore._client.list_collections():\n",
    "    ids = collection.get()['ids']\n",
    "    print('REMOVE %s document(s) from %s collection' % (str(len(ids)), collection.name))\n",
    "    if len(ids): collection.delete(ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "def delete_chromba_db():\n",
    "    directory_path=\"chroma_db\"\n",
    "    try:\n",
    "        # Use shutil.rmtree to delete the directory and its contents recursively\n",
    "        shutil.rmtree(directory_path)\n",
    "        print(f\"Directory '{directory_path}' successfully deleted.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting directory '{directory_path}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], template=\"<s> [INST] You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise. [/INST] </s> \\n[INST] Question: {question} \\nContext: {context} \\nAnswer: [/INST]\")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "QA_CHAIN_PROMPT = hub.pull(\"rlm/rag-prompt-mistral\") #rlm/rag-prompt-mistral\n",
    "QA_CHAIN_PROMPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## embbeding with Ollamaembedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Data and creating Vector\n",
    "loader=WebBaseLoader(\"https://en.wikipedia.org/wiki/Assam\")\n",
    "data=loader.load()\n",
    "\n",
    "text_splits=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=300)\n",
    "all_splits=text_splits.split_documents(data)\n",
    "print(len(all_splits))\n",
    "vectorstore = Chroma.from_documents(documents=all_splits,\n",
    "                                        embedding=OllamaEmbeddings(model=\"mistral\"), persist_directory=\"./chroma_db\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
